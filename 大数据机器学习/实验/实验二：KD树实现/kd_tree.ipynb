{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# 获取MNIST数据集,并抽样一部分数据以便后续的计算\n",
    "idx = np.random.choice(70000,5000,replace=False)\n",
    "mnist = fetch_openml(\"mnist_784\")\n",
    "X, y = mnist.data.to_numpy(), mnist.target.to_numpy().astype('int')\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "# 划分数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： (4000, 784)\n",
      "测试集大小： (1000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集大小：\",X_train.shape)\n",
    "print(\"测试集大小：\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于sklearn的kd树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 92.80%\n"
     ]
    }
   ],
   "source": [
    "# 创建KNeighborsClassifier模型，使用kd树作为搜索算法\n",
    "knn = KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree')\n",
    "\n",
    "# 在训练集上训练模型\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义kd树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN分类中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:22<00:00, 45.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 92.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 定义KD树节点类\n",
    "class Node:\n",
    "    def __init__(self, data, left=None, right=None):\n",
    "        self.data = data #节点本身的数据\n",
    "        self.left = left #节点的左子树\n",
    "        self.right = right #节点右子树\n",
    "\n",
    "# 递归方法构建KD树\n",
    "\n",
    "def build_kd_tree(X, depth=0):\n",
    "    if len(X) == 0:\n",
    "        return None\n",
    "    k = X.shape[1]\n",
    "    axis = depth % k #根据当前深度，选择划分的维度\n",
    "    X = X[X[:, axis].argsort()]\n",
    "    median = X.shape[0] // 2 #将当前结点数据一分为二\n",
    "    return Node(data=X[median], left=build_kd_tree(X[:median], depth + 1), right=build_kd_tree(X[median + 1:], depth + 1))\n",
    "\n",
    "# 计算点之间的距离，这里使用欧几里得距离\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "# 搜索KD树\n",
    "def search_kd_tree(tree, target, k=3):\n",
    "    if tree is None:\n",
    "        return []\n",
    "    k_nearest = [] # list用于储存target当前遍历到的k个k近邻\n",
    "    stack = [(tree, 0)] # 用于储存待遍历节点的stack\n",
    "    while stack:\n",
    "        node, depth = stack.pop() # 节点出栈\n",
    "        if node is None:\n",
    "            continue\n",
    "        distance = euclidean_distance(target, node.data) # 计算需要分类的目标点与节点的距离\n",
    "        if len(k_nearest) < k: # 当k_nearest未装满时，直接将节点放入\n",
    "            k_nearest.append((node.data, distance))\n",
    "        else: # 当k_nearest装满时，对比该节点与k_nearest中与目标点距离最远的节点的距离，如果小于则替换，如果大于则不替换\n",
    "            max_index = max(range(k), key=lambda i: k_nearest[i][1])\n",
    "            if k_nearest[max_index][1] > distance:\n",
    "                k_nearest[max_index] = (node.data, distance)\n",
    "        axis = depth % target.shape[0] # 计算当前深度对应的划分维度\n",
    "        axis_diff = target[axis] - node.data[axis] # 计算该维度下目标点与当前节点的差\n",
    "        if axis_diff <= 0: \n",
    "            # 当差小于0时，则该节点的左子树入栈 \n",
    "            # 如果k_nearest未装满或k_nearest中相距目标点最远的点与目标点的距离大于axis_diff的绝对值时，则右子树也入栈\n",
    "            stack.append((node.left, depth + 1))\n",
    "            if len(k_nearest) < k:\n",
    "                stack.append((node.right, depth + 1))\n",
    "            else:\n",
    "                max_index = max(range(k), key=lambda i: k_nearest[i][1])\n",
    "                if k_nearest[max_index][1] > abs(axis_diff):\n",
    "                    stack.append((node.right, depth + 1))\n",
    "        else:\n",
    "            # 当差大于0时，则该节点的右子树入栈\n",
    "            # 如果k_nearest未装满或k_nearest中相距目标点最远的点与目标点的距离大于axis_diff的绝对值时，则左子树也入栈\n",
    "            stack.append((node.right, depth + 1))\n",
    "            if len(k_nearest) < k:\n",
    "                stack.append((node.left, depth + 1))\n",
    "            else:\n",
    "                max_index = max(range(k), key=lambda i: k_nearest[i][1])\n",
    "                if k_nearest[max_index][1] > abs(axis_diff):\n",
    "                    stack.append((node.left, depth + 1))\n",
    "    return [data for data, _ in k_nearest] # 返回遍历完的kd树后的k_nearest\n",
    "\n",
    "\n",
    "# 使用KNN算法分类\n",
    "def knn_classifier(X_train, y_train, X_test, k=3):\n",
    "    y_pred = []\n",
    "    for test_point in tqdm(X_test):\n",
    "        k_nearest = search_kd_tree(kd_tree, test_point, k)\n",
    "        labels = [y_train[np.where((X_train == point).all(axis=1))[0][0]] for point in k_nearest]\n",
    "        counts = np.bincount(labels)#计算k_nearest中样本最多的标签，预测目标样本为该标签\n",
    "        y_pred.append(np.argmax(counts))\n",
    "    return y_pred\n",
    "\n",
    "# 构建KD树\n",
    "kd_tree = build_kd_tree(X_train)\n",
    "\n",
    "# 使用KNN算法进行分类\n",
    "k_neighbors = 3\n",
    "print(\"KNN分类中...\")\n",
    "y_pred = knn_classifier(X_train, y_train, X_test, k_neighbors)\n",
    "\n",
    "# 评估分类性能\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for k = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 55.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 1: 91.70%\n",
      "Searching for k = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 49.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 2: 91.30%\n",
      "Searching for k = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:21<00:00, 45.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 3: 92.80%\n",
      "Searching for k = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:23<00:00, 42.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 4: 91.90%\n",
      "Searching for k = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 5: 92.60%\n",
      "Searching for k = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 6: 92.20%\n",
      "Searching for k = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 7: 92.40%\n",
      "Searching for k = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:30<00:00, 33.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 8: 91.70%\n",
      "Searching for k = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:31<00:00, 31.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 9: 91.90%\n",
      "Searching for k = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy when k = 10: 91.30%\n",
      "The best k is 3 with accuracy 92.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # 超参数搜索，搜索k从1到10，输出使得模型性能最好的k\n",
    "\n",
    "best_acc = -np.inf\n",
    "\n",
    "for k in range(1, 11):\n",
    "    print(f\"Searching for k = {k}\")\n",
    "    y_pred_k = knn_classifier(X_train, y_train, X_test, k)\n",
    "    accuracy = accuracy_score(y_test, y_pred_k)\n",
    "    print(f\"KNN Accuracy when k = {k}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_k = k\n",
    "    \n",
    "print(f\"The best k is {best_k} with accuracy {best_acc * 100:.2f}%\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN(堆实现)分类中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 56.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy (堆实现): 91.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from heapq import heappush, heappop\n",
    "\n",
    "# 搜索KD的最大堆实现\n",
    "def search_kd_tree_heap(tree, target, k=3):\n",
    "    best_nodes = []  # 使用最大堆来存储最近邻\n",
    "    def visit_node(node, target, depth):\n",
    "        if node is None:\n",
    "            return\n",
    "        node_distance = euclidean_distance(target, node.data)\n",
    "\n",
    "        # 使用负距离以实现最大堆\n",
    "        if len(best_nodes) < k:\n",
    "            heappush(best_nodes, (-node_distance, tuple(node.data)))\n",
    "        elif -node_distance > best_nodes[0][0]:\n",
    "            heappop(best_nodes)\n",
    "            heappush(best_nodes, (-node_distance, tuple(node.data)))\n",
    "        \n",
    "        axis = depth % len(target)\n",
    "        next_node = node.left if target[axis] < node.data[axis] else node.right\n",
    "        other_node = node.right if next_node == node.left else node.left\n",
    "        \n",
    "        visit_node(next_node, target, depth + 1)\n",
    "\n",
    "        # 检查另一侧的子树是否有可能包含更近的点\n",
    "        if (len(best_nodes) < k or abs(target[axis] - node.data[axis]) < -best_nodes[0][0]):\n",
    "            visit_node(other_node, target, depth + 1)\n",
    "\n",
    "    visit_node(tree, target, 0)\n",
    "\n",
    "    return [data for _, data in best_nodes]\n",
    "\n",
    "# 使用KNN算法分类(堆实现)\n",
    "def knn_classifier_heap(X_train, y_train, X_test, k=3):\n",
    "    y_pred = []\n",
    "    for test_point in tqdm(X_test):\n",
    "        k_nearest = search_kd_tree_heap(kd_tree, test_point, k)\n",
    "        labels = [y_train[np.where((X_train == point).all(axis=1))[0][0]] for point in k_nearest]\n",
    "        counts = np.bincount(labels)#计算k_nearest中样本最多的标签，预测目标样本为该标签\n",
    "        y_pred.append(np.argmax(counts))\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "print(\"KNN(堆实现)分类中...\")\n",
    "k_neighbors = 2\n",
    "y_pred_heap = knn_classifier_heap(X_train, y_train, X_test, k_neighbors)\n",
    "\n",
    "accuracy_heap = accuracy_score(y_test, y_pred_heap)\n",
    "print(f\"KNN Accuracy (堆实现): {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
